{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP Class Assignment 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import spacy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing \n",
    "num_processors = multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "stopwords = set(nltk.corpus.stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read news data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample contains 10,012 news articles\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>date</th>\n",
       "      <th>language</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://kokomoperspective.com/obituaries/jon-w-horton/article_b6ba8e1e-cb9c-11eb-9868-fb11b88b9778.html</td>\n",
       "      <td>2021-06-13</td>\n",
       "      <td>en</td>\n",
       "      <td>Jon W. Horton | Obituaries | kokomoperspective.com</td>\n",
       "      <td>Jon W. Horton | Obituaries | kokomoperspective.comYou have permission to edit this article. EditCloseSign Up                        Log In                    Dashboard  LogoutMy Account Dashboard Profile Saved items LogoutCOVID-19Click here for the latest local news on COVID-19HomeAbout UsContact UsNewsLocalOpinionPoliticsNationalStateAgricultureLifestylesEngagements/Anniversaries/WeddingsAutosEntertainmentHealthHomesOutdoorsSportsNFLNCAAVitalsObituariesAutomotivee-EditionCouponsGalleries74¬∞...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://auto.economictimes.indiatimes.com/news/auto-components/birla-precision-to-ramp-up-capacity-to-tap-emerging-opportunities-in-india/81254902</td>\n",
       "      <td>2021-02-28</td>\n",
       "      <td>en</td>\n",
       "      <td>Birla Precision to ramp up capacity to tap emerging opportunities in India, Auto News, ET Auto</td>\n",
       "      <td>Birla Precision to ramp up capacity to tap emerging opportunities in India, Auto News, ET Auto     We have updated our terms and conditions and privacy policy Click \"Continue\" to accept and continue with ET AutoAccept the updated privacy &amp; cookie policyDear user, ET Auto privacy and cookie policy has been updated to align with the new data regulations in European Union. Please review and accept these changes below to continue using the website.You can see our privacy policy &amp; our cookie ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                  url  \\\n",
       "0                                              http://kokomoperspective.com/obituaries/jon-w-horton/article_b6ba8e1e-cb9c-11eb-9868-fb11b88b9778.html   \n",
       "1  https://auto.economictimes.indiatimes.com/news/auto-components/birla-precision-to-ramp-up-capacity-to-tap-emerging-opportunities-in-india/81254902   \n",
       "\n",
       "        date language  \\\n",
       "0 2021-06-13       en   \n",
       "1 2021-02-28       en   \n",
       "\n",
       "                                                                                                 title  \\\n",
       "0                                                   Jon W. Horton | Obituaries | kokomoperspective.com   \n",
       "1       Birla Precision to ramp up capacity to tap emerging opportunities in India, Auto News, ET Auto   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  text  \n",
       "0  Jon W. Horton | Obituaries | kokomoperspective.comYou have permission to edit this article. EditCloseSign Up                        Log In                    Dashboard  LogoutMy Account Dashboard Profile Saved items LogoutCOVID-19Click here for the latest local news on COVID-19HomeAbout UsContact UsNewsLocalOpinionPoliticsNationalStateAgricultureLifestylesEngagements/Anniversaries/WeddingsAutosEntertainmentHealthHomesOutdoorsSportsNFLNCAAVitalsObituariesAutomotivee-EditionCouponsGalleries74¬∞...  \n",
       "1      Birla Precision to ramp up capacity to tap emerging opportunities in India, Auto News, ET Auto     We have updated our terms and conditions and privacy policy Click \"Continue\" to accept and continue with ET AutoAccept the updated privacy & cookie policyDear user, ET Auto privacy and cookie policy has been updated to align with the new data regulations in European Union. Please review and accept these changes below to continue using the website.You can see our privacy policy & our cookie ...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_path = 'https://storage.googleapis.com/msca-bdp-data-open/news/nlp_a_5_news.json'\n",
    "news_df = pd.read_json(news_path, orient='records', lines=True)\n",
    "\n",
    "print(f'Sample contains {news_df.shape[0]:,.0f} news articles')\n",
    "news_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read Tweets data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample contains 10,105 tweets\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>lang</th>\n",
       "      <th>date</th>\n",
       "      <th>name</th>\n",
       "      <th>retweeted</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1534565117614084096</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-06-08</td>\n",
       "      <td>Low Orbit Tourist üåçüì∑</td>\n",
       "      <td></td>\n",
       "      <td>Body &amp;amp; Assembly - Halewood - United Kingdom\\nüåç53.3504,-2.8352296,402m\\n\\nHalewood Body &amp;amp; Assembly is a Jaguar Land Rover factory in Halewood, England, and forms the major part of the Halewood complex which is shared with Ford who manufacture transmissions at the site. [Wikipedia] https://t.co/LPmCnZIaVt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1534565743429394439</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-06-08</td>\n",
       "      <td>CompleteCar.ie</td>\n",
       "      <td>RT</td>\n",
       "      <td>Land Rover Ireland has announced that the new Range Rover Sport starts at ‚Ç¨114,150, now on @completecar:\\n\\nhttps://t.co/TjGUkL3FYr https://t.co/QdVaEiJkjO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id lang       date                  name retweeted  \\\n",
       "0  1534565117614084096   en 2022-06-08  Low Orbit Tourist üåçüì∑             \n",
       "1  1534565743429394439   en 2022-06-08        CompleteCar.ie        RT   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                       text  \n",
       "0  Body &amp; Assembly - Halewood - United Kingdom\\nüåç53.3504,-2.8352296,402m\\n\\nHalewood Body &amp; Assembly is a Jaguar Land Rover factory in Halewood, England, and forms the major part of the Halewood complex which is shared with Ford who manufacture transmissions at the site. [Wikipedia] https://t.co/LPmCnZIaVt  \n",
       "1                                                                                                                                                               Land Rover Ireland has announced that the new Range Rover Sport starts at ‚Ç¨114,150, now on @completecar:\\n\\nhttps://t.co/TjGUkL3FYr https://t.co/QdVaEiJkjO  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_path = 'https://storage.googleapis.com/msca-bdp-data-open/tweets/nlp_a_5_tweets.json'\n",
    "tweets_df = pd.read_json(tweets_path, orient='records', lines=True)\n",
    "print(f'Sample contains {tweets_df.shape[0]:,.0f} tweets')\n",
    "tweets_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "url         0\n",
       "date        0\n",
       "language    0\n",
       "title       0\n",
       "text        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id           0\n",
       "lang         0\n",
       "date         0\n",
       "name         0\n",
       "retweeted    0\n",
       "text         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 , 1\n"
     ]
    }
   ],
   "source": [
    "# Making sure that there are only english language articles and tweets\n",
    "print(news_df['language'].nunique(), ',',  tweets_df['lang'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping redundant columns\n",
    "news_df = news_df[['title', 'text']]\n",
    "tweets_df = tweets_df[['text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean text \n",
    "# It is necessary to preserve the text to identify of relevant entities\n",
    "# Hence, I did not remove any stop words\n",
    "def clean(df, col):\n",
    "    df[col] = df[col].str.strip()\n",
    "    pattern = r'\\||\\n|(@\\w+.*?)|(http\\w\\S+.*?)|(#\\w+)'\n",
    "    df[col] = df[col].apply(lambda x: re.sub(pattern, ' ', x)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean(news_df,'title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean(news_df,'text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean(tweets_df,'text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top company names using NER-NTLK, no segmentation\n",
    "def ner_nltk(df, col):\n",
    "    org = []\n",
    "    for text in df[col]:\n",
    "        ne_chunks = nltk.ne_chunk(nltk.pos_tag(nltk.word_tokenize(text)))\n",
    "        for chunk in ne_chunks:\n",
    "            if hasattr(chunk, 'label') and chunk.label() == 'ORGANIZATION':\n",
    "                org.extend([c for c in chunk])\n",
    "\n",
    "    org_counts = {}\n",
    "    for o in org:\n",
    "        if o[0] in org_counts:\n",
    "            org_counts[o[0]] += 1\n",
    "        else:\n",
    "            org_counts[o[0]] = 1\n",
    "\n",
    "    sorted_orgs = sorted(org_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "    top_orgs = sorted_orgs[:20]\n",
    "\n",
    "    return top_orgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('News', 675),\n",
       " ('Star', 292),\n",
       " ('Auto', 236),\n",
       " ('Online', 214),\n",
       " ('Mail', 213),\n",
       " ('Daily', 192),\n",
       " ('AutoSpies', 144),\n",
       " ('CoventryLive', 137),\n",
       " ('Business', 122),\n",
       " ('Automotive', 106),\n",
       " ('BMW', 95),\n",
       " ('Express', 94),\n",
       " ('NewsBreak', 92),\n",
       " ('Car', 92),\n",
       " ('Shropshire', 90),\n",
       " ('GMC', 87),\n",
       " ('ET', 77),\n",
       " ('UK', 77),\n",
       " ('Volkswagen', 74),\n",
       " ('Land', 66)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_nltk(news_df,'title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('LA', 1357),\n",
       " ('NYC', 1286),\n",
       " ('News', 1078),\n",
       " ('Princess', 1012),\n",
       " ('MailOnline', 925),\n",
       " ('Prince', 912),\n",
       " ('Kate', 893),\n",
       " ('VERY', 732),\n",
       " ('Queen', 626),\n",
       " ('UK', 623),\n",
       " ('Duke', 613),\n",
       " ('Royal', 599),\n",
       " ('Awards', 598),\n",
       " ('Of', 531),\n",
       " ('House', 517),\n",
       " ('US', 494),\n",
       " ('COVID', 482),\n",
       " ('Land', 458),\n",
       " ('THE', 431),\n",
       " ('Duchess', 429)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using a sample of text (10% of the whole corpus), since the running time is really long\n",
    "# Since the running time is very long, I did not combine title and text\n",
    "news_df_sample = news_df.sample(n = 1000, random_state = 420)\n",
    "ner_nltk(news_df_sample,'text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Land', 3441),\n",
       " ('Rover', 2796),\n",
       " ('BMW', 394),\n",
       " ('Discovery', 393),\n",
       " ('Motors', 314),\n",
       " ('General', 300),\n",
       " ('Jaguar', 294),\n",
       " ('LAND', 261),\n",
       " ('eBay', 223),\n",
       " ('UK', 204),\n",
       " ('Duke', 192),\n",
       " ('Duchess', 171),\n",
       " ('SHAMELESS', 157),\n",
       " ('Defender', 146),\n",
       " ('SUV', 136),\n",
       " ('Range', 119),\n",
       " ('Services', 114),\n",
       " ('Health', 106),\n",
       " ('Invictus', 94),\n",
       " ('ROVER', 89)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_nltk(tweets_df,'text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top company names using NER-NTLK, with segmentation\n",
    "def sent_tokenizer(df, col):\n",
    "    new_col_name = col + '_sent_tokens'\n",
    "    df[new_col_name] = df[col].apply(nltk.sent_tokenize)\n",
    "\n",
    "def ner_nltk_sent(df, col):\n",
    "    ORG=[]\n",
    "    for row in df[col]:\n",
    "        for sent in row:\n",
    "            for chunk in nltk.ne_chunk(nltk.pos_tag(nltk.word_tokenize(sent))):\n",
    "                if hasattr(chunk, 'label') and chunk.label() == 'ORGANIZATION':\n",
    "                    ORG.extend([c for c in chunk])\n",
    "                    \n",
    "    org_counts = {}\n",
    "    for org in ORG:\n",
    "        if org[0] in org_counts:\n",
    "            org_counts[org[0]] += 1\n",
    "        else:\n",
    "            org_counts[org[0]] = 1\n",
    "    \n",
    "    sorted_orgs = sorted(org_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "    top_orgs = sorted_orgs[:20]\n",
    "    \n",
    "    return top_orgs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('News', 675),\n",
       " ('Star', 289),\n",
       " ('Online', 238),\n",
       " ('Mail', 237),\n",
       " ('Auto', 236),\n",
       " ('Daily', 192),\n",
       " ('AutoSpies', 144),\n",
       " ('CoventryLive', 137),\n",
       " ('Business', 122),\n",
       " ('Automotive', 106),\n",
       " ('BMW', 96),\n",
       " ('Express', 94),\n",
       " ('NewsBreak', 92),\n",
       " ('Car', 92),\n",
       " ('Shropshire', 90),\n",
       " ('GMC', 87),\n",
       " ('ET', 77),\n",
       " ('UK', 77),\n",
       " ('Volkswagen', 74),\n",
       " ('Land', 66)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_tokenizer(news_df,'title')\n",
    "ner_nltk_sent(news_df,'title_sent_tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('LA', 1356),\n",
       " ('NYC', 1286),\n",
       " ('News', 1084),\n",
       " ('Princess', 1019),\n",
       " ('MailOnline', 925),\n",
       " ('Prince', 913),\n",
       " ('Kate', 868),\n",
       " ('VERY', 730),\n",
       " ('Queen', 627),\n",
       " ('UK', 623),\n",
       " ('Duke', 620),\n",
       " ('Royal', 600),\n",
       " ('Awards', 598),\n",
       " ('Of', 531),\n",
       " ('House', 523),\n",
       " ('US', 491),\n",
       " ('COVID', 483),\n",
       " ('Land', 465),\n",
       " ('Duchess', 416),\n",
       " ('Philip', 415)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_tokenizer(news_df,'text')\n",
    "sent_tokenizer(news_df_sample,'text')\n",
    "ner_nltk_sent(news_df_sample ,'text_sent_tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Land', 3448),\n",
       " ('Rover', 2846),\n",
       " ('Discovery', 394),\n",
       " ('BMW', 390),\n",
       " ('Motors', 314),\n",
       " ('Jaguar', 302),\n",
       " ('General', 300),\n",
       " ('LAND', 262),\n",
       " ('eBay', 223),\n",
       " ('UK', 204),\n",
       " ('Duke', 192),\n",
       " ('Duchess', 171),\n",
       " ('SHAMELESS', 157),\n",
       " ('Defender', 146),\n",
       " ('SUV', 136),\n",
       " ('Range', 119),\n",
       " ('Services', 114),\n",
       " ('Health', 106),\n",
       " ('Invictus', 94),\n",
       " ('ROVER', 90)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_tokenizer(tweets_df,'text')\n",
    "ner_nltk_sent(tweets_df,'text_sent_tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top company names using NER spaCy, no segmentation\n",
    "def ner_spacy(df, col):\n",
    "    entities = []\n",
    "    labels = []\n",
    "    for doc in nlp.pipe(df[col], batch_size=100):\n",
    "        entities.extend([ent.text for ent in doc.ents if ent.label_ == 'ORG'])\n",
    "        labels.extend([ent.label_ for ent in doc.ents if ent.label_ == 'ORG'])\n",
    "    ent_df = pd.DataFrame({'Entities':entities, 'Labels':labels})\n",
    "    ent_gpd = ent_df.groupby('Entities').count().sort_values(by='Labels', ascending=False).head(20)\n",
    "    \n",
    "    return ent_gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Entities</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Ford</th>\n",
       "      <td>265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hyundai</th>\n",
       "      <td>207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Star News</th>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chevrolet</th>\n",
       "      <td>165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Toyota</th>\n",
       "      <td>162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Honda</th>\n",
       "      <td>147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Shropshire Star</th>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Automotive News</th>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BMW</th>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Express &amp; Star</th>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RAM</th>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Otago Daily Times Online News</th>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ET Auto</th>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Auto News</th>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EV</th>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jeep</th>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nissan</th>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Volkswagen</th>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The China Post</th>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lexus</th>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Labels\n",
       "Entities                             \n",
       "Ford                              265\n",
       "Hyundai                           207\n",
       "Star News                         191\n",
       "Chevrolet                         165\n",
       "Toyota                            162\n",
       "Honda                             147\n",
       "Shropshire Star                   108\n",
       "Automotive News                   108\n",
       "BMW                               108\n",
       "Express & Star                    103\n",
       "RAM                                92\n",
       "Otago Daily Times Online News      88\n",
       "ET Auto                            76\n",
       "Auto News                          74\n",
       "EV                                 71\n",
       "Jeep                               69\n",
       "Nissan                             66\n",
       "Volkswagen                         55\n",
       "The China Post                     49\n",
       "Lexus                              47"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_spacy(news_df,'title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Entities</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Land Rover</th>\n",
       "      <td>1041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jaguar Land Rover</th>\n",
       "      <td>940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eBay</th>\n",
       "      <td>477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BMW</th>\n",
       "      <td>383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>General Motors</th>\n",
       "      <td>292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mercedes-Benz, Citroen</th>\n",
       "      <td>285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jaguar</th>\n",
       "      <td>175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ford</th>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Audi</th>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Volvo</th>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tesla</th>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bentley</th>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jeep</th>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mercedes</th>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mazda</th>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the Jaguar Land Rover Driving Challenge</th>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the SHAMELESS Health Services Board of Zimbabwe</th>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SHAMELESS</th>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Toyota</th>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VRM BR19</th>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Labels\n",
       "Entities                                               \n",
       "Land Rover                                         1041\n",
       "Jaguar Land Rover                                   940\n",
       "eBay                                                477\n",
       "BMW                                                 383\n",
       "General Motors                                      292\n",
       "Mercedes-Benz, Citroen                              285\n",
       "Jaguar                                              175\n",
       "Ford                                                116\n",
       "Audi                                                 99\n",
       "Volvo                                                93\n",
       "Tesla                                                88\n",
       "Bentley                                              76\n",
       "Jeep                                                 73\n",
       "Mercedes                                             68\n",
       "Mazda                                                66\n",
       "the Jaguar Land Rover Driving Challenge              66\n",
       "the SHAMELESS Health Services Board of Zimbabwe      64\n",
       "SHAMELESS                                            64\n",
       "Toyota                                               63\n",
       "VRM BR19                                             62"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_spacy(tweets_df,'text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Entities</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Land Rover</th>\n",
       "      <td>1041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jaguar Land Rover</th>\n",
       "      <td>940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eBay</th>\n",
       "      <td>477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BMW</th>\n",
       "      <td>383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>General Motors</th>\n",
       "      <td>292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mercedes-Benz, Citroen</th>\n",
       "      <td>285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jaguar</th>\n",
       "      <td>175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ford</th>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Audi</th>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Volvo</th>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tesla</th>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bentley</th>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jeep</th>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mercedes</th>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mazda</th>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the Jaguar Land Rover Driving Challenge</th>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the SHAMELESS Health Services Board of Zimbabwe</th>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SHAMELESS</th>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Toyota</th>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VRM BR19</th>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Labels\n",
       "Entities                                               \n",
       "Land Rover                                         1041\n",
       "Jaguar Land Rover                                   940\n",
       "eBay                                                477\n",
       "BMW                                                 383\n",
       "General Motors                                      292\n",
       "Mercedes-Benz, Citroen                              285\n",
       "Jaguar                                              175\n",
       "Ford                                                116\n",
       "Audi                                                 99\n",
       "Volvo                                                93\n",
       "Tesla                                                88\n",
       "Bentley                                              76\n",
       "Jeep                                                 73\n",
       "Mercedes                                             68\n",
       "Mazda                                                66\n",
       "the Jaguar Land Rover Driving Challenge              66\n",
       "the SHAMELESS Health Services Board of Zimbabwe      64\n",
       "SHAMELESS                                            64\n",
       "Toyota                                               63\n",
       "VRM BR19                                             62"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_spacy(tweets_df,'text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top company names using NER spaCy, with segmentation\n",
    "def ner_spacy_sent(df, col):\n",
    "    entities = []\n",
    "    labels = []\n",
    "    for row in df[col]:\n",
    "        doc = nlp(' '.join(row))  # join the tokens of the row into a single string\n",
    "        for ent in doc.ents:\n",
    "            if ent.label_ == 'ORG':\n",
    "                entities.append(ent.text)\n",
    "                labels.append(ent.label_)\n",
    "    ent_df = pd.DataFrame({'Entities': entities, 'Labels': labels})\n",
    "    ent_gpd = ent_df.groupby('Entities').count().sort_values(by='Labels', ascending=False).head(20)\n",
    "    return ent_gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Entities</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Ford</th>\n",
       "      <td>265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hyundai</th>\n",
       "      <td>207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Star News</th>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chevrolet</th>\n",
       "      <td>165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Toyota</th>\n",
       "      <td>162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Honda</th>\n",
       "      <td>147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Automotive News</th>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BMW</th>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Shropshire Star</th>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Express &amp; Star</th>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RAM</th>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Otago Daily Times Online News</th>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ET Auto</th>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Auto News</th>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EV</th>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jeep</th>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nissan</th>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Volkswagen</th>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The China Post</th>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lexus</th>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Labels\n",
       "Entities                             \n",
       "Ford                              265\n",
       "Hyundai                           207\n",
       "Star News                         191\n",
       "Chevrolet                         165\n",
       "Toyota                            162\n",
       "Honda                             147\n",
       "Automotive News                   108\n",
       "BMW                               108\n",
       "Shropshire Star                   106\n",
       "Express & Star                    103\n",
       "RAM                                92\n",
       "Otago Daily Times Online News      88\n",
       "ET Auto                            76\n",
       "Auto News                          74\n",
       "EV                                 71\n",
       "Jeep                               69\n",
       "Nissan                             66\n",
       "Volkswagen                         55\n",
       "The China Post                     49\n",
       "Lexus                              47"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = ner_spacy_sent(news_df, 'title_sent_tokens') \n",
    "\n",
    "# create an empty DataFrame\n",
    "results_org_df = pd.DataFrame()  \n",
    "results_org_df = results_org_df.append(temp)\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Entities</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MailOnline</th>\n",
       "      <td>864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ford</th>\n",
       "      <td>643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>COVID-19</th>\n",
       "      <td>642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Toyota</th>\n",
       "      <td>527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Instagram</th>\n",
       "      <td>405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hyundai</th>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Honda</th>\n",
       "      <td>391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trump</th>\n",
       "      <td>376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BMW</th>\n",
       "      <td>369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Amazon</th>\n",
       "      <td>366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Netflix</th>\n",
       "      <td>348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EV</th>\n",
       "      <td>326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>COVID</th>\n",
       "      <td>312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Palace</th>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>House</th>\n",
       "      <td>283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Britney Spears</th>\n",
       "      <td>260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Duke</th>\n",
       "      <td>232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Apple</th>\n",
       "      <td>225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nissan</th>\n",
       "      <td>223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BBC</th>\n",
       "      <td>222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Labels\n",
       "Entities              \n",
       "MailOnline         864\n",
       "Ford               643\n",
       "COVID-19           642\n",
       "Toyota             527\n",
       "Instagram          405\n",
       "Hyundai            400\n",
       "Honda              391\n",
       "Trump              376\n",
       "BMW                369\n",
       "Amazon             366\n",
       "Netflix            348\n",
       "EV                 326\n",
       "COVID              312\n",
       "Palace             300\n",
       "House              283\n",
       "Britney Spears     260\n",
       "Duke               232\n",
       "Apple              225\n",
       "Nissan             223\n",
       "BBC                222"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = ner_spacy_sent(news_df_sample,'text_sent_tokens')\n",
    "\n",
    "results_org_df = results_org_df.append(temp)\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Entities</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Land Rover</th>\n",
       "      <td>1049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jaguar Land Rover</th>\n",
       "      <td>951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eBay</th>\n",
       "      <td>476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BMW</th>\n",
       "      <td>383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>General Motors</th>\n",
       "      <td>292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mercedes-Benz, Citroen</th>\n",
       "      <td>285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jaguar</th>\n",
       "      <td>175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ford</th>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Audi</th>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Volvo</th>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tesla</th>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bentley</th>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jeep</th>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mercedes</th>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mazda</th>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the Jaguar Land Rover Driving Challenge</th>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SHAMELESS</th>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the SHAMELESS Health Services Board of Zimbabwe</th>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Toyota</th>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VRM BR19</th>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Labels\n",
       "Entities                                               \n",
       "Land Rover                                         1049\n",
       "Jaguar Land Rover                                   951\n",
       "eBay                                                476\n",
       "BMW                                                 383\n",
       "General Motors                                      292\n",
       "Mercedes-Benz, Citroen                              285\n",
       "Jaguar                                              175\n",
       "Ford                                                116\n",
       "Audi                                                100\n",
       "Volvo                                                94\n",
       "Tesla                                                88\n",
       "Bentley                                              76\n",
       "Jeep                                                 73\n",
       "Mercedes                                             68\n",
       "Mazda                                                66\n",
       "the Jaguar Land Rover Driving Challenge              66\n",
       "SHAMELESS                                            64\n",
       "the SHAMELESS Health Services Board of Zimbabwe      64\n",
       "Toyota                                               63\n",
       "VRM BR19                                             62"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = ner_spacy_sent(tweets_df,'text_sent_tokens')\n",
    "\n",
    "results_org_df = results_org_df.append(temp)\n",
    "temp "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top location names using NER-NTLK\n",
    "def ner_nltk_loc(df, col):\n",
    "    loc_counts = {}\n",
    "    for text in df[col]:\n",
    "        for chunk in nltk.ne_chunk(nltk.pos_tag(nltk.word_tokenize(text))):\n",
    "            if isinstance(chunk, nltk.tree.Tree) and chunk.label() == 'GPE':\n",
    "                loc = ' '.join([token[0] for token in chunk])\n",
    "                loc_counts[loc] = loc_counts.get(loc, 0) + 1\n",
    "    \n",
    "    top_20_locs = sorted(loc_counts.items(), key=lambda x: x[1], reverse=True)[:20]\n",
    "    \n",
    "    return top_20_locs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Sale', 1951),\n",
       " ('British', 231),\n",
       " ('Prince', 144),\n",
       " ('New', 139),\n",
       " ('Winnipeg', 137),\n",
       " ('India', 126),\n",
       " ('Toronto', 118),\n",
       " ('London', 113),\n",
       " ('Roadshow', 110),\n",
       " ('Cambridge', 92),\n",
       " ('North York', 72),\n",
       " ('Driven', 68),\n",
       " ('U.S.', 67),\n",
       " ('News', 63),\n",
       " ('Calgary', 63),\n",
       " ('China', 58),\n",
       " ('Daily', 57),\n",
       " ('Taiwan', 57),\n",
       " ('Mississauga', 55),\n",
       " ('Land', 52)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_nltk_loc(news_df,'title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('London', 1160),\n",
       " ('Los Angeles', 941),\n",
       " ('British', 777),\n",
       " ('New York City', 774),\n",
       " ('New York', 570),\n",
       " ('India', 520),\n",
       " ('West', 450),\n",
       " ('Australia', 419),\n",
       " ('Miami', 416),\n",
       " ('California', 407),\n",
       " ('American', 380),\n",
       " ('China', 365),\n",
       " ('Malibu', 364),\n",
       " ('U.S.', 359),\n",
       " ('Facebook', 347),\n",
       " ('Britain', 343),\n",
       " ('Mexico', 339),\n",
       " ('Australian', 328),\n",
       " ('Paris', 328),\n",
       " ('Sydney', 323)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_nltk_loc(news_df_sample,'text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Land', 1470),\n",
       " ('Russia', 180),\n",
       " ('British', 155),\n",
       " ('Jaguar', 124),\n",
       " ('Sussex', 119),\n",
       " ('India', 92),\n",
       " ('Zimbabwe', 86),\n",
       " ('New', 84),\n",
       " ('Ad', 83),\n",
       " ('Russian', 77),\n",
       " ('Audi', 70),\n",
       " ('Cambridge', 68),\n",
       " ('Car', 68),\n",
       " ('Britain', 64),\n",
       " ('Meghan', 64),\n",
       " ('Paracetamol', 64),\n",
       " ('LAND', 63),\n",
       " ('UPDATE', 54),\n",
       " ('Indian', 53),\n",
       " ('Netherlands', 52)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_nltk_loc(tweets_df,'text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top location names using spaCy\n",
    "def ner_spacy_loc(df, col):\n",
    "    entities = [ent.text for i in df[col] for ent in nlp(i).ents if ent.label_ == 'GPE']\n",
    "    entity_counts = Counter(entities)\n",
    "    top_20_locs = entity_counts.most_common(20)\n",
    "    return top_20_locs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Carpages.ca', 1962),\n",
       " ('Ontario', 1265),\n",
       " ('British Columbia', 198),\n",
       " ('UK', 195),\n",
       " ('Manitoba', 181),\n",
       " ('Winnipeg', 137),\n",
       " ('India', 121),\n",
       " ('Toronto', 118),\n",
       " ('Alberta', 116),\n",
       " ('London', 112),\n",
       " ('Cambridge', 90),\n",
       " ('US', 82),\n",
       " ('Saskatchewan', 78),\n",
       " ('North York', 72),\n",
       " ('Calgary', 64),\n",
       " ('U.S.', 64),\n",
       " ('China', 59),\n",
       " ('Taiwan', 54),\n",
       " ('Kitchener', 44),\n",
       " ('Australia', 44)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = ner_spacy_loc(news_df,'title') \n",
    "\n",
    "# create an empty DataFrame\n",
    "results_loc_df = pd.DataFrame()  \n",
    "results_loc_df = results_loc_df.append(temp)\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('LA', 1872),\n",
       " ('London', 1258),\n",
       " ('UK', 1221),\n",
       " ('US', 1039),\n",
       " ('Los Angeles', 997),\n",
       " ('New York City', 739),\n",
       " ('Hollywood', 595),\n",
       " ('India', 550),\n",
       " ('Miami', 476),\n",
       " ('Meghan', 475),\n",
       " ('New York', 467),\n",
       " ('Australia', 463),\n",
       " ('California', 437),\n",
       " ('West Hollywood', 432),\n",
       " ('Beverly Hills', 423),\n",
       " ('Sydney', 419),\n",
       " ('China', 383),\n",
       " ('Britain', 370),\n",
       " ('Mexico', 366),\n",
       " ('Malibu', 354)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = ner_spacy_loc(news_df_sample,'text')\n",
    "\n",
    "results_loc_df = results_loc_df.append(temp)\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = ner_spacy_loc(tweets_df,'text')\n",
    "\n",
    "results_loc_df = results_loc_df.append(temp)\n",
    "temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: The NER-NLTK and SpaCy models take a significant amount of time to run on the entire corpus of text data. Therefore, to optimize the processing time, a sample of 10% of the corpus was used instead of the entire corpus. Additionally, to further save time, the analysis was performed separately on the titles and text data, instead of combining them into one dataset. This allowed for more efficient processing and analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"display:inline\" border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Entities</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Ford</th>\n",
       "      <td>265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hyundai</th>\n",
       "      <td>207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Star News</th>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chevrolet</th>\n",
       "      <td>165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Toyota</th>\n",
       "      <td>162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Honda</th>\n",
       "      <td>147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Automotive News</th>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BMW</th>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Shropshire Star</th>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Express &amp; Star</th>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RAM</th>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Otago Daily Times Online News</th>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ET Auto</th>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Auto News</th>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EV</th>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jeep</th>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nissan</th>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Volkswagen</th>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The China Post</th>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lexus</th>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table style=\"display:inline\"><table style=\"display:inline\" border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Entities</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MailOnline</th>\n",
       "      <td>864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ford</th>\n",
       "      <td>643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>COVID-19</th>\n",
       "      <td>642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Toyota</th>\n",
       "      <td>527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Instagram</th>\n",
       "      <td>405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hyundai</th>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Honda</th>\n",
       "      <td>391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trump</th>\n",
       "      <td>376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BMW</th>\n",
       "      <td>369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Amazon</th>\n",
       "      <td>366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Netflix</th>\n",
       "      <td>348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EV</th>\n",
       "      <td>326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>COVID</th>\n",
       "      <td>312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Palace</th>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>House</th>\n",
       "      <td>283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Britney Spears</th>\n",
       "      <td>260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Duke</th>\n",
       "      <td>232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Apple</th>\n",
       "      <td>225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nissan</th>\n",
       "      <td>223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BBC</th>\n",
       "      <td>222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table style=\"display:inline\"><table style=\"display:inline\" border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Entities</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Land Rover</th>\n",
       "      <td>1049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jaguar Land Rover</th>\n",
       "      <td>951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eBay</th>\n",
       "      <td>476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BMW</th>\n",
       "      <td>383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>General Motors</th>\n",
       "      <td>292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mercedes-Benz, Citroen</th>\n",
       "      <td>285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jaguar</th>\n",
       "      <td>175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ford</th>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Audi</th>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Volvo</th>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tesla</th>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bentley</th>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jeep</th>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mercedes</th>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mazda</th>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the Jaguar Land Rover Driving Challenge</th>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SHAMELESS</th>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the SHAMELESS Health Services Board of Zimbabwe</th>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Toyota</th>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VRM BR19</th>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table style=\"display:inline\">"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df1, df2, df3 = np.array_split(results_org_df, 3)\n",
    "\n",
    "# display the three dataframes side by side\n",
    "from IPython.display import display_html\n",
    "\n",
    "html_str = ''\n",
    "for df in [df1, df2, df3]:\n",
    "    html_str += df.to_html()\n",
    "display_html(html_str.replace('table', 'table style='display:inline''), raw=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: The above tables are displayed in order: Entities in News Titles, News Text, Tweets\n",
    "\n",
    "Based on the tables above, we can conclude that the NER-NLTK model doesn't perform well in identifying organizations as it misidentifies a lot of other words such as News, LA, NYC, etc. However, for tweets, the model performs slightly better as it correctly identifies companies such as Land Rover, BMW, and Jaguar. Additionally, the SpaCy model performs much better than NER-NLTK in correctly identifying company names with few exceptions. The model's performance is also better when sentence segmentation is used compared to only word tokenization since the former helps in identifying the context in most cases.\n",
    "\n",
    "Hence, **spaCy with Segmentation is the best performing model.**\n",
    "\n",
    "In terms of company mentions, for news article titles, the most frequently mentioned company is Ford, followed by Hyundai, Chevrolet, Toyota, and Honda. In the case of news article text, the most frequently mentioned company is Ford, followed by Toyota, Hyundai, Honda, and BMW. For tweets, the most frequently mentioned company is Land Rover, followed by Jaguar, BMW, General Motors, Mercedes-Benz, and Ford."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"display:inline\" border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Carpages.ca</td>\n",
       "      <td>1962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ontario</td>\n",
       "      <td>1265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>British Columbia</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UK</td>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Manitoba</td>\n",
       "      <td>181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Winnipeg</td>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>India</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Toronto</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Alberta</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>London</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Cambridge</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>US</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Saskatchewan</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>North York</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Calgary</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>U.S.</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>China</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Taiwan</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Kitchener</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Australia</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table style=\"display:inline\"><table style=\"display:inline\" border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LA</td>\n",
       "      <td>1872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>London</td>\n",
       "      <td>1258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UK</td>\n",
       "      <td>1221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>US</td>\n",
       "      <td>1039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>New York City</td>\n",
       "      <td>739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Hollywood</td>\n",
       "      <td>595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>India</td>\n",
       "      <td>550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Miami</td>\n",
       "      <td>476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Meghan</td>\n",
       "      <td>475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>New York</td>\n",
       "      <td>467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Australia</td>\n",
       "      <td>463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>California</td>\n",
       "      <td>437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>West Hollywood</td>\n",
       "      <td>432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Beverly Hills</td>\n",
       "      <td>423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Sydney</td>\n",
       "      <td>419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>China</td>\n",
       "      <td>383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Britain</td>\n",
       "      <td>370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Mexico</td>\n",
       "      <td>366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Malibu</td>\n",
       "      <td>354</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table style=\"display:inline\"><table style=\"display:inline\" border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UK</td>\n",
       "      <td>342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Russia</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>India</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Meghan</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kibaki</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Britain</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Jamaica</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Netherlands</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>üí∏</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>The Hague</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>London</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>China</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>South Africa</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Bridgwater</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>US</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>France</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>New Zealand</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Hollywood</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Nyeri</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table style=\"display:inline\">"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df1, df2, df3 = np.array_split(results_loc_df, 3)\n",
    "\n",
    "# display the three dataframes side by side\n",
    "from IPython.display import display_html\n",
    "\n",
    "html_str = ''\n",
    "for df in [df1, df2, df3]:\n",
    "    html_str += df.to_html()\n",
    "display_html(html_str.replace('table', 'table style='display:inline''), raw=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: The above tables are displayed in order: Entities in News Titles, News Text, Tweets\n",
    "\n",
    "Based on the results, it can be observed that the NER-SpaCy model outperforms the NER-NLTK model in accurately identifying locations. The NER-NLTK model produces a lot of false positive results, such as identifying 'Land' as a location, when in fact it refers to the company Land Rover. In contrast, the SpaCy model shows very few exceptions in identifying locations correctly.\n",
    "\n",
    "Hence, **spaCy with Segmentation is the best performing model.** \n",
    "\n",
    "In terms of the most frequently mentioned locations, the titles of news articles frequently mention Ontario as the top location, followed by British Columbia, Uk, and Manitoba. For the text in news articles, LA is the most frequently mentioned location, followed by London, UK, and US. Lastly, for tweets, UK is the most frequently mentioned location, followed by Russia, India, and Britain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
